{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2025-02-09T07:15:51.692414Z",
          "iopub.status.busy": "2025-02-09T07:15:51.692145Z",
          "iopub.status.idle": "2025-02-09T07:15:51.698440Z",
          "shell.execute_reply": "2025-02-09T07:15:51.697490Z",
          "shell.execute_reply.started": "2025-02-09T07:15:51.692393Z"
        },
        "trusted": true,
        "id": "mcqzFrbsc1iE",
        "outputId": "7a5ff095-1c08-48b9-a12e-80e8611979ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/330k-arabic-sentiment-reviews/arabic_sentiment_reviews.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:15:53.321201Z",
          "iopub.status.busy": "2025-02-09T07:15:53.320933Z",
          "iopub.status.idle": "2025-02-09T07:15:53.325020Z",
          "shell.execute_reply": "2025-02-09T07:15:53.324226Z",
          "shell.execute_reply.started": "2025-02-09T07:15:53.321178Z"
        },
        "trusted": true,
        "id": "_eYduhbZc1iJ"
      },
      "outputs": [],
      "source": [
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = 'all'\n",
        "# to run more than output in the same cell\n",
        "pd.set_option('display.max_colwidth', None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:15:54.819886Z",
          "iopub.status.busy": "2025-02-09T07:15:54.819612Z",
          "iopub.status.idle": "2025-02-09T07:16:01.020232Z",
          "shell.execute_reply": "2025-02-09T07:16:01.019399Z",
          "shell.execute_reply.started": "2025-02-09T07:15:54.819856Z"
        },
        "trusted": true,
        "id": "XPJEKl8vc1iK",
        "outputId": "13be4cc7-d5f8-497e-b06c-8332250201dc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>النعال المريحة: أرتدي هذه النعال كثيرًا!فهي دافئة ومريحة وبأسعار معقولة لجودة رائعة.زوجي وأنا على حد سواء لدينا زوج ونحن نحبهم!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>منتج جميل ، خدمة سيئة: لقد اشتريت زوجًا من النعال الباو الدب.باتباع إرشادات وصف المنتج ، ارتفعت حجمًا للتناسب.عندما وصلوا ، كانوا لطيفين حقًا وأحبوا.كانت كبيرة جدا.حاولت إعادة ترتيب ولم تكن متوفرة.حاولت الاتصال بـ Claussette عبر الهاتف وقيل لها البريد الإلكتروني.لقد أرسلت عبر البريد الإلكتروني معضلي وانتظرت أسبوعًا ، ولم ترد ، لقد أرسلت رسالتي الإلكترونية مرة أخرى ، قبل ثلاثة أيام.لا يوجد استجابة.أريد فقط استبدال العنصر ، أو الحصول على إجابة.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>جيد للأشياء الصغيرة: هذا يعمل بشكل جيد لالتقاط قطع صغيرة من المجوهرات ، ولكن الذهاب ببطء.إنه مفيد ، لكن المغناطيس ليس قويًا جدًا.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>واهية للغاية: flimsyif للغاية ، فأنت تشتريه ، كن حذرًا جدًا للغاية مع إطالة وتقصيره ، وأي استخدام على الإطلاق على الإطلاق.(بلا ​​مزاح)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Pop for Girls and Girly Boys ، والأشخاص الذين يحبون الضحك: عليك فقط أن تبتسم عندما تستمع إلى Book of Love ، وهم فرقة كلها هناك ، وهم ممتعون عندما لا تأخذهم إلى جادة.ليس عليك أن تكون مثليًا للاستمتاع بموسيقى ولكنها ستساعد ، أو على الأقل ودية.شرائه فقط للابتسام ، وشعر بالدوار والغموض في الداخل.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  \\\n",
              "0      1   \n",
              "1      1   \n",
              "2      1   \n",
              "3      0   \n",
              "4      1   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                          content  \n",
              "0                                                                                                                                                                                                                                                                                                                                 النعال المريحة: أرتدي هذه النعال كثيرًا!فهي دافئة ومريحة وبأسعار معقولة لجودة رائعة.زوجي وأنا على حد سواء لدينا زوج ونحن نحبهم!  \n",
              "1  منتج جميل ، خدمة سيئة: لقد اشتريت زوجًا من النعال الباو الدب.باتباع إرشادات وصف المنتج ، ارتفعت حجمًا للتناسب.عندما وصلوا ، كانوا لطيفين حقًا وأحبوا.كانت كبيرة جدا.حاولت إعادة ترتيب ولم تكن متوفرة.حاولت الاتصال بـ Claussette عبر الهاتف وقيل لها البريد الإلكتروني.لقد أرسلت عبر البريد الإلكتروني معضلي وانتظرت أسبوعًا ، ولم ترد ، لقد أرسلت رسالتي الإلكترونية مرة أخرى ، قبل ثلاثة أيام.لا يوجد استجابة.أريد فقط استبدال العنصر ، أو الحصول على إجابة.  \n",
              "2                                                                                                                                                                                                                                                                                                                               جيد للأشياء الصغيرة: هذا يعمل بشكل جيد لالتقاط قطع صغيرة من المجوهرات ، ولكن الذهاب ببطء.إنه مفيد ، لكن المغناطيس ليس قويًا جدًا.  \n",
              "3                                                                                                                                                                                                                                                                                                                          واهية للغاية: flimsyif للغاية ، فأنت تشتريه ، كن حذرًا جدًا للغاية مع إطالة وتقصيره ، وأي استخدام على الإطلاق على الإطلاق.(بلا ​​مزاح)  \n",
              "4                                                                                                                                                           Pop for Girls and Girly Boys ، والأشخاص الذين يحبون الضحك: عليك فقط أن تبتسم عندما تستمع إلى Book of Love ، وهم فرقة كلها هناك ، وهم ممتعون عندما لا تأخذهم إلى جادة.ليس عليك أن تكون مثليًا للاستمتاع بموسيقى ولكنها ستساعد ، أو على الأقل ودية.شرائه فقط للابتسام ، وشعر بالدوار والغموض في الداخل.  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(os.path.join(dirname, filename))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rp_gjnxEc1iL"
      },
      "source": [
        "## This cell removes non-Arabic characters from the text data in the content column and creates a new column cleaned_content with the cleaned text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:16:01.021745Z",
          "iopub.status.busy": "2025-02-09T07:16:01.021480Z",
          "iopub.status.idle": "2025-02-09T07:16:06.443512Z",
          "shell.execute_reply": "2025-02-09T07:16:06.442570Z",
          "shell.execute_reply.started": "2025-02-09T07:16:01.021725Z"
        },
        "trusted": true,
        "id": "lJzZfOcwc1iM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "arabic_pattern = re.compile(r'[^أ-يء \\s]+')\n",
        "def remove_non_arabic(text):\n",
        "    return arabic_pattern.sub('', text)\n",
        "\n",
        "df['content'] = df['content'].apply(lambda str : str.replace(\".\", \" \").strip())\n",
        "df['cleaned_content'] = df['content'].apply(remove_non_arabic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCTpiw33c1iN"
      },
      "source": [
        "## This cell balances the dataset by ensuring an equal number of samples for each class. It then shuffles the dataset to avoid any bias and prints the new class ((((distribution))))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-02-09T07:16:06.445056Z",
          "iopub.status.busy": "2025-02-09T07:16:06.444777Z",
          "iopub.status.idle": "2025-02-09T07:16:06.757847Z",
          "shell.execute_reply": "2025-02-09T07:16:06.756932Z",
          "shell.execute_reply.started": "2025-02-09T07:16:06.445020Z"
        },
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "vgFR9cJkc1iN",
        "outputId": "46ed2dde-99a5-434d-b423-b91487e6bedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Class Distribution:\n",
            " label\n",
            "1    166853\n",
            "0    163147\n",
            "Name: count, dtype: int64\n",
            "Reduced Class Distribution:\n",
            " label\n",
            "0    82500\n",
            "1    82500\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-6-b319e797ff44>:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_balanced = df.groupby(\"label\").apply(lambda x: x.sample(n=samples_per_class, random_state=42)).reset_index(drop=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "label    165000.0\n",
              "Name: count, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>content</th>\n",
              "      <th>cleaned_content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ما يسمى 2 Pack Louis de Funes: إحدى الحزم تحتوي على أفلام تحتوي على القليل جدًا من Louis de Funes ، ويتصرف في حالة من القلقات الصغيرة جدًا كلتا الحزمتين باللغة الفرنسية تمامًا فقط بدون ترجمة لأي لغة أخرى على الإطلاق بخيبة أمل كبيرة في حين أن كل أقراص DVD أخرى لديها ترجمات نصح بالبقاء واضحًا ما لم يكن المرء يجيد الفرنسية</td>\n",
              "      <td>ما يسمى      إحدى الحزم تحتوي على أفلام تحتوي على القليل جدا من     ويتصرف في حالة من القلقات الصغيرة جدا كلتا الحزمتين باللغة الفرنسية تماما فقط بدون ترجمة لأي لغة أخرى على الإطلاق بخيبة أمل كبيرة في حين أن كل أقراص  أخرى لديها ترجمات نصح بالبقاء واضحا ما لم يكن المرء يجيد الفرنسية</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>كان يمكن أن يكون مضحكا ، ولكن لا    : التمثيل الرهيب ، وكوبا هي الفائز في الأكاديمية السابقة؟هذا أمر مفرط في الإفراط في الإحراج ، ناهيك عن الإحراج - وهذا أمر جيد بالنسبة لنماذج Feautering ، ولكن بالنسبة للجهات الفاعلة الجادة مثل كوبا ، فهذا ليس كذلك كان من الممكن أن يكون اثنان من جنسين مختلفين يصطدمان بمثليي الجنس ، لكن التمثيل السيئ الذي تليه مؤامرة غبية لقصة يجعلها واحدة من أقل الكوميديا المضحكة التي رأيتها على الإطلاق آسف كوبا</td>\n",
              "      <td>كان يمكن أن يكون مضحكا  ولكن لا     التمثيل الرهيب  وكوبا هي الفائز في الأكاديمية السابقةهذا أمر مفرط في الإفراط في الإحراج  ناهيك عن الإحراج  وهذا أمر جيد بالنسبة لنماذج   ولكن بالنسبة للجهات الفاعلة الجادة مثل كوبا  فهذا ليس كذلك كان من الممكن أن يكون اثنان من جنسين مختلفين يصطدمان بمثليي الجنس  لكن التمثيل السيئ الذي تليه مؤامرة غبية لقصة يجعلها واحدة من أقل الكوميديا المضحكة التي رأيتها على الإطلاق سف كوبا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>مؤامرة متقطعة مع شخصيات غير أصلية: قصة مخيبة للآمال عن أطفال داميا ومآثرهم \"العظيمة\" تحاول القصة تغطية أكبر قدر ممكن من الوقت والعمل في عدد قليل من الكلمات قدر الإمكان ، مما يخلق مؤامرة مفككة ورقيقة من الصعب بعض الشيء متابعة هناك الكثير من الثغرات ؛ليس أحد أفضل أعمال ماكافري وكان موضوع التمييز المضاد للعنصري متعبًا وملبًا ، وهو فاكس باهت لسلسلة Ender الخاصة بـ Orson Scott Card التي هي أفضل بكثير وأكثر استفزازية سيئة للغاية كان لديها إمكانات</td>\n",
              "      <td>مؤامرة متقطعة مع شخصيات غير أصلية قصة مخيبة للمال عن أطفال داميا ومثرهم العظيمة تحاول القصة تغطية أكبر قدر ممكن من الوقت والعمل في عدد قليل من الكلمات قدر الإمكان  مما يخلق مؤامرة مفككة ورقيقة من الصعب بعض الشيء متابعة هناك الكثير من الثغرات ليس أحد أفضل أعمال ماكافري وكان موضوع التمييز المضاد للعنصري متعبا وملبا  وهو فاكس باهت لسلسلة  الخاصة بـ    التي هي أفضل بكثير وأكثر استفزازية سيئة للغاية كان لديها إمكانات</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>ليس كل هذا سيئًا: هذا هو أول سجل أملكه على الإطلاق - هدية عطلة عندما كان عمري 7 سنوات أفترض أن هذا هو أول تسجيل للرجل هو أول تسجيل للرجل للصرخ بصوت عالٍ يعود تاريخه إلى عام 1972 ، لذلك إذا بدا الأمر غير تقليدي بعض الشيء ، فمن المحتمل أن يكون ذلك أحب أن أستمع إلى هذا كأساس لمعرفة مدى وصوله ، وكيف نضج على مدار 30 عامًا (قليلاً جدًا)وجود كذلك إنه جزء من تاريخه - ويصيبه إنها بدايته ومع ذلك ، فإنه ليس عملاً رائعًا ، ولا من هو اليوم بالنسبة إلى غير ، فإن هذا سيبدو قديمًا ، قديمًا ، مبتذلاً</td>\n",
              "      <td>ليس كل هذا سيئا هذا هو أول سجل أملكه على الإطلاق  هدية عطلة عندما كان عمري  سنوات أفترض أن هذا هو أول تسجيل للرجل هو أول تسجيل للرجل للصرخ بصوت عال يعود تاريخه إلى عام   لذلك إذا بدا الأمر غير تقليدي بعض الشيء  فمن المحتمل أن يكون ذلك أحب أن أستمع إلى هذا كأساس لمعرفة مدى وصوله  وكيف نضج على مدار  عاما قليلا جداوجود كذلك إنه جزء من تاريخه  ويصيبه إنها بدايته ومع ذلك  فإنه ليس عملا رائعا  ولا من هو اليوم بالنسبة إلى غير  فإن هذا سيبدو قديما  قديما  مبتذلا</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>حذار الفريسيون!: طبقة من الطبقة ، هذا الكتاب يرفع كل شيء يجعل المرء \"طيبة\": الاكتفاء الذاتي ، وبرد الذات ، والنفاق ، والشرعية ، والكمال ، والروح القضائية ، والغطرسة ، والأنانية ، والفخر ما تبقى في النهاية هو الروح الحقيقية للحياة المسيحية والخدمة: الاعتماد التام على نعمة الله ، والامتنان العميق والمستمر لخلاصه ، وتجدد الاحترام والتعاطف مع النفوس الأخرى المتعثرة ، والتواضع ، والصدق ، والكرم ، والصبر ، والفرح ،دهشة هذا الكتاب مكتوب بشكل ممتاز ويظهر نظرة عميقة على الأمثال والتعاليم الأخرى ليسوع ، والتي تم توجيه الكثير منها إلى الفريسيين في يومه سيكون كل من يقرأ هذا الكتاب أفضل بشكل أساسي-حتى الفريسي المتمرد حقًا الذي قد يبدأ الكتاب معتقدين أنه مكتوب عن شخص آخر</td>\n",
              "      <td>حذار الفريسيون طبقة من الطبقة  هذا الكتاب يرفع كل شيء يجعل المرء طيبة الاكتفاء الذاتي  وبرد الذات  والنفاق  والشرعية  والكمال  والروح القضائية  والغطرسة  والأنانية  والفخر ما تبقى في النهاية هو الروح الحقيقية للحياة المسيحية والخدمة الاعتماد التام على نعمة الله  والامتنان العميق والمستمر لخلاصه  وتجدد الاحترام والتعاطف مع النفوس الأخرى المتعثرة  والتواضع  والصدق  والكرم  والصبر  والفرح دهشة هذا الكتاب مكتوب بشكل ممتاز ويظهر نظرة عميقة على الأمثال والتعاليم الأخرى ليسوع  والتي تم توجيه الكثير منها إلى الفريسيين في يومه سيكون كل من يقرأ هذا الكتاب أفضل بشكل أساسيحتى الفريسي المتمرد حقا الذي قد يبدأ الكتاب معتقدين أنه مكتوب عن شخص خر</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  \\\n",
              "0      0   \n",
              "1      0   \n",
              "2      0   \n",
              "3      1   \n",
              "4      1   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     content  \\\n",
              "0                                                                                                                                                                                                                                                                                                                                                          ما يسمى 2 Pack Louis de Funes: إحدى الحزم تحتوي على أفلام تحتوي على القليل جدًا من Louis de Funes ، ويتصرف في حالة من القلقات الصغيرة جدًا كلتا الحزمتين باللغة الفرنسية تمامًا فقط بدون ترجمة لأي لغة أخرى على الإطلاق بخيبة أمل كبيرة في حين أن كل أقراص DVD أخرى لديها ترجمات نصح بالبقاء واضحًا ما لم يكن المرء يجيد الفرنسية   \n",
              "1                                                                                                                                                                                                                                          كان يمكن أن يكون مضحكا ، ولكن لا    : التمثيل الرهيب ، وكوبا هي الفائز في الأكاديمية السابقة؟هذا أمر مفرط في الإفراط في الإحراج ، ناهيك عن الإحراج - وهذا أمر جيد بالنسبة لنماذج Feautering ، ولكن بالنسبة للجهات الفاعلة الجادة مثل كوبا ، فهذا ليس كذلك كان من الممكن أن يكون اثنان من جنسين مختلفين يصطدمان بمثليي الجنس ، لكن التمثيل السيئ الذي تليه مؤامرة غبية لقصة يجعلها واحدة من أقل الكوميديا المضحكة التي رأيتها على الإطلاق آسف كوبا   \n",
              "2                                                                                                                                                                                                                               مؤامرة متقطعة مع شخصيات غير أصلية: قصة مخيبة للآمال عن أطفال داميا ومآثرهم \"العظيمة\" تحاول القصة تغطية أكبر قدر ممكن من الوقت والعمل في عدد قليل من الكلمات قدر الإمكان ، مما يخلق مؤامرة مفككة ورقيقة من الصعب بعض الشيء متابعة هناك الكثير من الثغرات ؛ليس أحد أفضل أعمال ماكافري وكان موضوع التمييز المضاد للعنصري متعبًا وملبًا ، وهو فاكس باهت لسلسلة Ender الخاصة بـ Orson Scott Card التي هي أفضل بكثير وأكثر استفزازية سيئة للغاية كان لديها إمكانات   \n",
              "3                                                                                                                                                                                   ليس كل هذا سيئًا: هذا هو أول سجل أملكه على الإطلاق - هدية عطلة عندما كان عمري 7 سنوات أفترض أن هذا هو أول تسجيل للرجل هو أول تسجيل للرجل للصرخ بصوت عالٍ يعود تاريخه إلى عام 1972 ، لذلك إذا بدا الأمر غير تقليدي بعض الشيء ، فمن المحتمل أن يكون ذلك أحب أن أستمع إلى هذا كأساس لمعرفة مدى وصوله ، وكيف نضج على مدار 30 عامًا (قليلاً جدًا)وجود كذلك إنه جزء من تاريخه - ويصيبه إنها بدايته ومع ذلك ، فإنه ليس عملاً رائعًا ، ولا من هو اليوم بالنسبة إلى غير ، فإن هذا سيبدو قديمًا ، قديمًا ، مبتذلاً   \n",
              "4  حذار الفريسيون!: طبقة من الطبقة ، هذا الكتاب يرفع كل شيء يجعل المرء \"طيبة\": الاكتفاء الذاتي ، وبرد الذات ، والنفاق ، والشرعية ، والكمال ، والروح القضائية ، والغطرسة ، والأنانية ، والفخر ما تبقى في النهاية هو الروح الحقيقية للحياة المسيحية والخدمة: الاعتماد التام على نعمة الله ، والامتنان العميق والمستمر لخلاصه ، وتجدد الاحترام والتعاطف مع النفوس الأخرى المتعثرة ، والتواضع ، والصدق ، والكرم ، والصبر ، والفرح ،دهشة هذا الكتاب مكتوب بشكل ممتاز ويظهر نظرة عميقة على الأمثال والتعاليم الأخرى ليسوع ، والتي تم توجيه الكثير منها إلى الفريسيين في يومه سيكون كل من يقرأ هذا الكتاب أفضل بشكل أساسي-حتى الفريسي المتمرد حقًا الذي قد يبدأ الكتاب معتقدين أنه مكتوب عن شخص آخر   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  cleaned_content  \n",
              "0                                                                                                                                                                                                                                                                                                                                                                     ما يسمى      إحدى الحزم تحتوي على أفلام تحتوي على القليل جدا من     ويتصرف في حالة من القلقات الصغيرة جدا كلتا الحزمتين باللغة الفرنسية تماما فقط بدون ترجمة لأي لغة أخرى على الإطلاق بخيبة أمل كبيرة في حين أن كل أقراص  أخرى لديها ترجمات نصح بالبقاء واضحا ما لم يكن المرء يجيد الفرنسية  \n",
              "1                                                                                                                                                                                                                                   كان يمكن أن يكون مضحكا  ولكن لا     التمثيل الرهيب  وكوبا هي الفائز في الأكاديمية السابقةهذا أمر مفرط في الإفراط في الإحراج  ناهيك عن الإحراج  وهذا أمر جيد بالنسبة لنماذج   ولكن بالنسبة للجهات الفاعلة الجادة مثل كوبا  فهذا ليس كذلك كان من الممكن أن يكون اثنان من جنسين مختلفين يصطدمان بمثليي الجنس  لكن التمثيل السيئ الذي تليه مؤامرة غبية لقصة يجعلها واحدة من أقل الكوميديا المضحكة التي رأيتها على الإطلاق سف كوبا  \n",
              "2                                                                                                                                                                                                                                 مؤامرة متقطعة مع شخصيات غير أصلية قصة مخيبة للمال عن أطفال داميا ومثرهم العظيمة تحاول القصة تغطية أكبر قدر ممكن من الوقت والعمل في عدد قليل من الكلمات قدر الإمكان  مما يخلق مؤامرة مفككة ورقيقة من الصعب بعض الشيء متابعة هناك الكثير من الثغرات ليس أحد أفضل أعمال ماكافري وكان موضوع التمييز المضاد للعنصري متعبا وملبا  وهو فاكس باهت لسلسلة  الخاصة بـ    التي هي أفضل بكثير وأكثر استفزازية سيئة للغاية كان لديها إمكانات  \n",
              "3                                                                                                                                                                                      ليس كل هذا سيئا هذا هو أول سجل أملكه على الإطلاق  هدية عطلة عندما كان عمري  سنوات أفترض أن هذا هو أول تسجيل للرجل هو أول تسجيل للرجل للصرخ بصوت عال يعود تاريخه إلى عام   لذلك إذا بدا الأمر غير تقليدي بعض الشيء  فمن المحتمل أن يكون ذلك أحب أن أستمع إلى هذا كأساس لمعرفة مدى وصوله  وكيف نضج على مدار  عاما قليلا جداوجود كذلك إنه جزء من تاريخه  ويصيبه إنها بدايته ومع ذلك  فإنه ليس عملا رائعا  ولا من هو اليوم بالنسبة إلى غير  فإن هذا سيبدو قديما  قديما  مبتذلا  \n",
              "4  حذار الفريسيون طبقة من الطبقة  هذا الكتاب يرفع كل شيء يجعل المرء طيبة الاكتفاء الذاتي  وبرد الذات  والنفاق  والشرعية  والكمال  والروح القضائية  والغطرسة  والأنانية  والفخر ما تبقى في النهاية هو الروح الحقيقية للحياة المسيحية والخدمة الاعتماد التام على نعمة الله  والامتنان العميق والمستمر لخلاصه  وتجدد الاحترام والتعاطف مع النفوس الأخرى المتعثرة  والتواضع  والصدق  والكرم  والصبر  والفرح دهشة هذا الكتاب مكتوب بشكل ممتاز ويظهر نظرة عميقة على الأمثال والتعاليم الأخرى ليسوع  والتي تم توجيه الكثير منها إلى الفريسيين في يومه سيكون كل من يقرأ هذا الكتاب أفضل بشكل أساسيحتى الفريسي المتمرد حقا الذي قد يبدأ الكتاب معتقدين أنه مكتوب عن شخص خر  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get class counts\n",
        "class_counts = df[\"label\"].value_counts()\n",
        "print(\"Original Class Distribution:\\n\", class_counts)\n",
        "\n",
        "# Calculate half the dataset size\n",
        "total_size = len(df) // 2\n",
        "\n",
        "# Determine the maximum number of samples per class while keeping balance\n",
        "samples_per_class = total_size // len(class_counts)\n",
        "\n",
        "# Sample from each class equally\n",
        "df_balanced = df.groupby(\"label\").apply(lambda x: x.sample(n=samples_per_class, random_state=42)).reset_index(drop=True)\n",
        "\n",
        "# Shuffle the dataset to avoid ordering bias\n",
        "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Print new class distribution\n",
        "print(\"Reduced Class Distribution:\\n\", df_balanced[\"label\"].value_counts())\n",
        "df = df_balanced\n",
        "df.describe().iloc[0]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFvSkNm2c1iO"
      },
      "source": [
        "## This cell visualizes the class distribution after balancing using a count plot.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T08:15:01.999916Z",
          "iopub.status.busy": "2025-02-09T08:15:01.999581Z",
          "iopub.status.idle": "2025-02-09T08:15:02.416268Z",
          "shell.execute_reply": "2025-02-09T08:15:02.415405Z",
          "shell.execute_reply.started": "2025-02-09T08:15:01.999892Z"
        },
        "trusted": true,
        "id": "Guu_IHvnc1iP",
        "outputId": "666e1f9f-76a1-4b94-9eb6-8baddb94f2c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 0 Axes>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "<Axes: xlabel='label', ylabel='count'>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Class Label')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Class Distribution After Balancing')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Plot class distribution\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x=df[\"label\"], palette=\"viridis\")\n",
        "\n",
        "# Labels and title\n",
        "plt.xlabel(\"Class Label\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Class Distribution After Balancing\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6s1_FNAc1iP"
      },
      "source": [
        "## This cell sets up the environment for model training by importing necessary libraries and disabling tokenizer parallelism to prevent hanging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:16:18.878736Z",
          "iopub.status.busy": "2025-02-09T07:16:18.878423Z",
          "iopub.status.idle": "2025-02-09T07:16:40.679474Z",
          "shell.execute_reply": "2025-02-09T07:16:40.678589Z",
          "shell.execute_reply.started": "2025-02-09T07:16:18.878707Z"
        },
        "trusted": true,
        "id": "s-vp-3W6c1iQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import (AutoModel, AutoTokenizer, Trainer, TrainingArguments,\n",
        "                          BertForSequenceClassification, DataCollatorWithPadding)\n",
        "import os\n",
        "from datasets import Dataset\n",
        "\n",
        "# Disable tokenizer parallelism to prevent hanging\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEfVEXRBc1iQ"
      },
      "source": [
        "##  This cell loads the tokenizer and model, defines a preprocessing function, converts the DataFrame to a Dataset, splits it into training and testing sets, tokenizes the dataset, and sets up a data collator for padding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:16:43.962534Z",
          "iopub.status.busy": "2025-02-09T07:16:43.961866Z",
          "iopub.status.idle": "2025-02-09T07:17:45.599268Z",
          "shell.execute_reply": "2025-02-09T07:17:45.598579Z",
          "shell.execute_reply.started": "2025-02-09T07:16:43.962500Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "c3401627723a4e03bdc0311a3f652851",
            "291add35c4b64b52aef7c97a549d790a",
            "f27f526a70854fda9725c69033a9e25b",
            "52c2a0d9c5ca4a87af8cf5fb1430fb5a",
            "89e0a0a3e0da4b3d9e1495dc58da3be4",
            "7cac1a4fb40c4d42b482b4eb84c97f3f",
            "c26eed3fda934f0eacb5a3c73ea0390d"
          ]
        },
        "id": "mSHxDyZMc1iQ",
        "outputId": "0695f679-6753-439c-9658-76ac1e1304e2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3401627723a4e03bdc0311a3f652851",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/62.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "291add35c4b64b52aef7c97a549d790a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/491 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f27f526a70854fda9725c69033a9e25b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/334k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52c2a0d9c5ca4a87af8cf5fb1430fb5a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89e0a0a3e0da4b3d9e1495dc58da3be4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at asafaya/bert-base-arabic and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7cac1a4fb40c4d42b482b4eb84c97f3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/115500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c26eed3fda934f0eacb5a3c73ea0390d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/49500 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"asafaya/bert-base-arabic\")\n",
        "sequence_clf_model = BertForSequenceClassification.from_pretrained(\"asafaya/bert-base-arabic\", num_labels=2)\n",
        "\n",
        "# Define max length\n",
        "max_length = 300\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"cleaned_content\"], truncation=True, max_length=max_length)\n",
        "    tokenized_inputs[\"labels\"] = examples[\"label\"]  # Ensure labels are included\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Convert dataframe to Dataset\n",
        "classification_dataset = Dataset.from_pandas(df)\n",
        "\n",
        "# Split dataset\n",
        "classification_dataset = classification_dataset.train_test_split(test_size=0.3)\n",
        "\n",
        "# Tokenize dataset\n",
        "seq_clf_tokenized = classification_dataset.map(preprocess_function, batched=True, remove_columns=[\"cleaned_content\", \"label\"])\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:18:00.955007Z",
          "iopub.status.busy": "2025-02-09T07:18:00.954711Z",
          "iopub.status.idle": "2025-02-09T07:18:05.554343Z",
          "shell.execute_reply": "2025-02-09T07:18:05.553626Z",
          "shell.execute_reply.started": "2025-02-09T07:18:00.954983Z"
        },
        "trusted": true,
        "id": "IX_exFTcc1iR",
        "outputId": "aada26d4-2fee-482a-81b4-82101bfa9c68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.28.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
            "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
            "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n",
            "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n",
            "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
            "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n",
            "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
            "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate\n",
        "import evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU0DV04Ac1iR"
      },
      "source": [
        "`eval_pred` is a tuple containing:\n",
        "- logits: The raw outputs from the model (before applying softmax).\n",
        "- labels: The true class labels.\n",
        "\n",
        "**Logits** are the raw, unnormalized scores that your model outputs before applying a softmax function to convert them into probabilities.\n",
        "\n",
        "Each row represents a prediction for a single input, and each column corresponds to a class.\n",
        "\n",
        "For example:\n",
        "\n",
        "Logits Sample: `[-1.8190521  1.8116069]`\n",
        "Class 0 score: -1.8190521\n",
        "Class 1 score: 1.8116069\n",
        "\n",
        "**Labels** Sample: `[1, 0, 1, 1, 0]` represents the true class labels for the corresponding predictions.\n",
        "\n",
        "1 means the correct class is Class 1.\n",
        "0 means the correct class is Class 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLuSqyuec1iR"
      },
      "source": [
        "## This cell defines a function to compute evaluation metrics (accuracy) based on the model's predictions and true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:18:13.771479Z",
          "iopub.status.busy": "2025-02-09T07:18:13.771121Z",
          "iopub.status.idle": "2025-02-09T07:18:13.776300Z",
          "shell.execute_reply": "2025-02-09T07:18:13.775366Z",
          "shell.execute_reply.started": "2025-02-09T07:18:13.771448Z"
        },
        "trusted": true,
        "id": "To6P1q5Gc1iR"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1) # Get Predicted Classes\n",
        "\n",
        "    # Debugging >> Print first few logits\n",
        "    print(f\"Logits Sample: {logits[:5]}\")\n",
        "    print(f\"Labels Sample: {labels[:5]}\")\n",
        "\n",
        "    accuracy = np.mean(predictions == labels)#creates a boolean array then  Calculates the proportion of correct predictions.\n",
        "    return {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:31:52.702475Z",
          "iopub.status.busy": "2025-02-09T07:31:52.702135Z",
          "iopub.status.idle": "2025-02-09T07:31:52.707452Z",
          "shell.execute_reply": "2025-02-09T07:31:52.706634Z",
          "shell.execute_reply.started": "2025-02-09T07:31:52.702442Z"
        },
        "trusted": true,
        "id": "4HKS22rjc1iS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": np.mean(predictions == labels),\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8MnZ5mqc1iS"
      },
      "source": [
        "## يتم في هذه الخلية إنشاء مجموعة فرعية أصغر من مجموعة بيانات التقييم لتقييم أسرع أثناء التدريب"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:18:45.751973Z",
          "iopub.status.busy": "2025-02-09T07:18:45.751664Z",
          "iopub.status.idle": "2025-02-09T07:18:45.772902Z",
          "shell.execute_reply": "2025-02-09T07:18:45.772312Z",
          "shell.execute_reply.started": "2025-02-09T07:18:45.751948Z"
        },
        "trusted": true,
        "id": "Aa2bKGJtc1iS"
      },
      "outputs": [],
      "source": [
        "subset_size = int(len( seq_clf_tokenized[\"test\"])/2)\n",
        "\n",
        "# Select a random subset of the evaluation dataset\n",
        "eval_subset = seq_clf_tokenized[\"test\"].shuffle(seed=42).select(range(subset_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "TUYq5zyUc1iS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": false,
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2025-02-09T04:59:27.267084Z",
          "iopub.status.busy": "2025-02-09T04:59:27.266761Z",
          "iopub.status.idle": "2025-02-09T05:35:57.531180Z",
          "shell.execute_reply": "2025-02-09T05:35:57.528916Z",
          "shell.execute_reply.started": "2025-02-09T04:59:27.267051Z"
        },
        "jupyter": {
          "outputs_hidden": true,
          "source_hidden": true
        },
        "trusted": true,
        "id": "aoLzqnIGc1iS"
      },
      "outputs": [],
      "source": [
        "## Define training arguments\n",
        "# -----------------------\n",
        "epochs = 1 #the number of epochs\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./clf/results\",\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    load_best_model_at_end=True,c\n",
        "    weight_decay=0.05,\n",
        "    logging_steps=5,\n",
        "    log_level='info',\n",
        "    evaluation_strategy='steps',\n",
        "    save_strategy='steps',\n",
        "    eval_steps=5,  # Evaluate every 5 steps\n",
        "    save_steps=500,  # Save every 500 steps\n",
        "    fp16=True,\n",
        "    report_to=\"none\"  # Disable WandB logging\n",
        ")\n",
        "\n",
        "# Define trainer يتم تحديد كل التوبيكس ومن ثم بدء عملية التدريب\n",
        "trainer = Trainer(\n",
        "    model=sequence_clf_model,\n",
        "    args=training_args,\n",
        "    train_dataset=seq_clf_tokenized[\"train\"],\n",
        "    eval_dataset=eval_subset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T07:31:56.758930Z",
          "iopub.status.busy": "2025-02-09T07:31:56.758632Z",
          "iopub.status.idle": "2025-02-09T08:14:00.102080Z",
          "shell.execute_reply": "2025-02-09T08:14:00.101388Z",
          "shell.execute_reply.started": "2025-02-09T07:31:56.758906Z"
        },
        "trusted": true,
        "id": "sCvl37AJc1iT",
        "outputId": "deae84fa-bbf8-41b2-862d-cc6c1ff7561a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "PyTorch: setting up devices\n",
            "Using auto half precision backend\n",
            "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: content. If content are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 115,500\n",
            "  Num Epochs = 1\n",
            "  Instantaneous batch size per device = 32\n",
            "  Training with DataParallel so batch size has been adjusted to: 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1,805\n",
            "  Number of trainable parameters = 110,618,882\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1805' max='1805' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1805/1805 42:01, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.223600</td>\n",
              "      <td>0.261182</td>\n",
              "      <td>0.911030</td>\n",
              "      <td>0.911540</td>\n",
              "      <td>0.911030</td>\n",
              "      <td>0.911010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.222600</td>\n",
              "      <td>0.195728</td>\n",
              "      <td>0.922384</td>\n",
              "      <td>0.924267</td>\n",
              "      <td>0.922384</td>\n",
              "      <td>0.922286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.179900</td>\n",
              "      <td>0.174590</td>\n",
              "      <td>0.931596</td>\n",
              "      <td>0.931797</td>\n",
              "      <td>0.931596</td>\n",
              "      <td>0.931591</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: content. If content are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./clf/results/checkpoint-500\n",
            "Configuration saved in ./clf/results/checkpoint-500/config.json\n",
            "Model weights saved in ./clf/results/checkpoint-500/model.safetensors\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn(\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: content. If content are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./clf/results/checkpoint-1000\n",
            "Configuration saved in ./clf/results/checkpoint-1000/config.json\n",
            "Model weights saved in ./clf/results/checkpoint-1000/model.safetensors\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn(\n",
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: content. If content are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 24750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./clf/results/checkpoint-1500\n",
            "Configuration saved in ./clf/results/checkpoint-1500/config.json\n",
            "Model weights saved in ./clf/results/checkpoint-1500/model.safetensors\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn(\n",
            "Saving model checkpoint to ./clf/results/checkpoint-1805\n",
            "Configuration saved in ./clf/results/checkpoint-1805/config.json\n",
            "Model weights saved in ./clf/results/checkpoint-1805/model.safetensors\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./clf/results/checkpoint-1500 (score: 0.17458979785442352).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1805, training_loss=0.1709752635240885, metrics={'train_runtime': 2522.4422, 'train_samples_per_second': 45.789, 'train_steps_per_second': 0.716, 'total_flos': 1.030837048240608e+16, 'train_loss': 0.1709752635240885, 'epoch': 1.0})"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Define training arguments\n",
        "# -----------------------\n",
        "epochs = 1\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./clf/results\",\n",
        "    num_train_epochs=epochs,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    load_best_model_at_end=True,\n",
        "    weight_decay=0.05,\n",
        "    logging_steps=5,#1 step = single update of the  parameters\n",
        "    log_level='info',\n",
        "    evaluation_strategy='steps',\n",
        "    save_strategy='steps',\n",
        "    eval_steps=500,  # Evaluate every 500 steps\n",
        "    save_steps=500,  # Save every 500 steps\n",
        "    fp16=True,\n",
        "    report_to=\"none\"  # Disable WandB logging\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=sequence_clf_model,\n",
        "    args=training_args,\n",
        "    train_dataset=seq_clf_tokenized[\"train\"],\n",
        "    eval_dataset=eval_subset,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWPzXzlWc1iT"
      },
      "source": [
        "## فيما يلي  يتم في هذه الخلايا تحميل أفضل نقطة تحقق للنموذج التي تم حفظها أثناء التدريب"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T08:21:49.686328Z",
          "iopub.status.busy": "2025-02-09T08:21:49.685529Z",
          "iopub.status.idle": "2025-02-09T08:21:49.690080Z",
          "shell.execute_reply": "2025-02-09T08:21:49.689160Z",
          "shell.execute_reply.started": "2025-02-09T08:21:49.686295Z"
        },
        "trusted": true,
        "id": "0AF30iZFc1iT"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T08:22:52.745380Z",
          "iopub.status.busy": "2025-02-09T08:22:52.745005Z",
          "iopub.status.idle": "2025-02-09T08:22:52.748742Z",
          "shell.execute_reply": "2025-02-09T08:22:52.747956Z",
          "shell.execute_reply.started": "2025-02-09T08:22:52.745349Z"
        },
        "trusted": true,
        "id": "N98fVzlUc1iT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T08:23:51.344436Z",
          "iopub.status.busy": "2025-02-09T08:23:51.344098Z",
          "iopub.status.idle": "2025-02-09T08:23:51.414034Z",
          "shell.execute_reply": "2025-02-09T08:23:51.413202Z",
          "shell.execute_reply.started": "2025-02-09T08:23:51.344407Z"
        },
        "trusted": true,
        "id": "NN7xK6R2c1iT",
        "outputId": "75a193cd-f4b5-4704-c147-d4b0d513cd73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file ./clf/results/checkpoint-1500/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"./clf/results/checkpoint-1500\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.47.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file ./clf/results/checkpoint-1500/model.safetensors\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ./clf/results/checkpoint-1500.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "best_model = trainer.model\n",
        "\n",
        "best_model_path = \"./clf/results/checkpoint-1500\"  # the best checkpoint\n",
        "best_model = AutoModelForSequenceClassification.from_pretrained(best_model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-02-09T08:24:08.235296Z",
          "iopub.status.busy": "2025-02-09T08:24:08.234945Z",
          "iopub.status.idle": "2025-02-09T08:29:21.708150Z",
          "shell.execute_reply": "2025-02-09T08:29:21.707264Z",
          "shell.execute_reply.started": "2025-02-09T08:24:08.235251Z"
        },
        "trusted": true,
        "id": "yAT1Mtync1iU",
        "outputId": "ce675b4d-e035-4fcd-f07e-5f42ddbce09e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: content. If content are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 49500\n",
            "  Batch size = 64\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='774' max='774' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [774/774 05:12]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.17154347896575928,\n",
              " 'eval_accuracy': 0.933010101010101,\n",
              " 'eval_precision': 0.9331713932932488,\n",
              " 'eval_recall': 0.933010101010101,\n",
              " 'eval_f1': 0.933005893963128,\n",
              " 'eval_runtime': 313.4636,\n",
              " 'eval_samples_per_second': 157.913,\n",
              " 'eval_steps_per_second': 2.469,\n",
              " 'epoch': 1.0}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run evaluation on test dataset explicitly\n",
        "test_results = trainer.evaluate(eval_dataset=seq_clf_tokenized[\"test\"])\n",
        "\n",
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "s3zQ0aR0c1iU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 5577640,
          "sourceId": 9222859,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30887,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}